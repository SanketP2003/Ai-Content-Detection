spring.application.name=ai-backend
server.port=8080

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=mistral:7b
spring.ai.ollama.chat.options.num_ctx=4096
spring.ai.ollama.chat.options.num_predict=4096
ai.model.api.url=http://localhost:11434/api/generate

# Disable MVC autoconfig
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration

# Enable WebFlux
spring.main.web-application-type=reactive

spring.main.allow-circular-references=true
-Dio.netty.tryReflectionSetAccessible=true